{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 쇼핑리뷰 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\"\n",
    "df = pd.read_table(url, names=['score', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199335, 2)\n",
      "199335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                   배공빠르고 굿\n",
       "1                             택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2         아주좋아요 바지 정말 좋아서 개 더 구매했어요 이가격에 대박입니다  바느질이 조금 ...\n",
       "3         선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다  전...\n",
       "4                         민트색상 예뻐요  옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ\n",
       "                                ...                        \n",
       "199995                                      장마라그런가    달지않아요\n",
       "199996    다이슨 케이스 구매했어요 다이슨 슈퍼소닉 드라이기 케이스 구매했어요가격 괜찮고 배송...\n",
       "199997                      로드샾에서 사는것보다 세배 저렴하네요 ㅜㅜ 자주이용할께요\n",
       "199998                                         넘이쁘고 쎄련되보이네요\n",
       "199999     아직 사용해보지도않았고 다른 제품을 써본적이없어서 잘 모르겠지만 ㅎㅎ 배송은 빨랐습니다\n",
       "Name: review, Length: 199335, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ 1. 데이터/텍스트 전처리를 하세요.(결측치, 중복데이터, 한글 이외의 데이터 제거등)(20)\n",
    "\n",
    "# 평점 4, 5 점 -> 긍정(1), 나머지는 부정(0)\n",
    "df.score = df.score.apply(lambda x: 1 if x >= 4 else 0 )\n",
    "\n",
    "# 결측치\n",
    "df.isna().sum().sum()\n",
    "\n",
    "# 중복 데이터\n",
    "print(df.shape)\n",
    "print(df.review.nunique())\n",
    "df.drop_duplicates(subset=['review'], inplace=True)\n",
    "# 한글 이외의 데이터, ''를 제거\n",
    "df.review = df.review.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]', ' ', regex=True).str.strip()\n",
    "df.review.replace('', np.nan, inplace=True)\n",
    "df.isna().sum().sum()   # 발생하지 않았음\n",
    "\n",
    "df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 2. Okt를 사용하여 한글 형태소 분석을 하세요.(10)\n",
    "\n",
    "with open('data/불용어.txt') as st:\n",
    "    lines = st.readlines()\n",
    "stop_words = [line.split('\\t')[0] for line in lines]\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "def okt_tokenizer(text):    # tokenizer함수는 ver1의 문자열 변환과정 대신해줌\n",
    "    morphs = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in morphs if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3. CountVectorizer와 LogisticRegression을 이용하여 이진 분류를 하되, 최적의 파라메터를 도출하고 분류 정확도를 표시하세요.(20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.review.values, df.score.values, stratify=df.score.values,\n",
    "    test_size=0.2, random_state=2023\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer(tokenizer=okt_tokenizer)\n",
    "cvect.fit(X_train)\n",
    "X_train_cv = cvect.transform(X_train)\n",
    "X_test_cv = cvect.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=2023, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 학습\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('cvect', cvect),('lr', lr)])\n",
    "params = {'cvect__max_df': [300, 700], 'lr__C': [1, 10]}\n",
    "grid_pipe = GridSearchCV(pipeline, params, scoring='accuracy', cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe.best_estimator_.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
